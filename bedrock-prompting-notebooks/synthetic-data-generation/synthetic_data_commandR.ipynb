{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a29f818-7dac-48dd-9ca5-8c1965424173",
   "metadata": {},
   "source": [
    "# Prompt Engineering for Synthetic Data Generation Using Cohere Command R Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd487a-81ee-4b9c-9987-440e0a0b5143",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "In this notebook we step through how to leverage Cohere Command R family of models to create synthetic data based on provided schemas. The use case for this notebook is a health social media app. The health app includes different posts on the platform for users as well as user profiles for the health application. We begin with having these schemas defined and the LLM will use the schemas to generate the data. We will step throug how to ingest this data into Opensearch and then query the results to confirm the data resides in the Opensearch Collection.\n",
    "\n",
    "This solution is intended to help teams and developers quickly build test data for various use cases whether the search engine is Opensearch or other data stores like relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc5723-7765-47a9-b829-e62581bd9fa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "## Cohere Command R Models\n",
    "There are multiple different models available on Amazon Bedrock from Cohere Command R family of models:\n",
    "\n",
    "### 1. Command R+\n",
    "- **Description:** Command R+ is Cohere's most powerful generative language model optimized for long-context tasks, such as retrieval-augmented generation (RAG) and multi-step tool use.\n",
    "- **MaxTokens:** 128K\n",
    "- **Languages:** English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, and Chinese\n",
    "- **Supported Use cases:** Text generation, text summarization, chat, knowledge assistants, Q&A, RAG.\n",
    "\n",
    "### 2. Command R\n",
    "- **Description:** Command R is Cohere's generative language model optimized for long-context tasks, such as retrieval-augmented generation (RAG) and tools, and large scale production workloads.\n",
    "- **MaxTokens:** 128K\n",
    "- **Languages:** English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, and Chinese\n",
    "- **Supported Use cases:** Text generation, text summarization, chat, knowledge assistants, Q&A, RAG.\n",
    "\n",
    "For the notebook, we will use Command R+ model as default with the option to switch to Command R to test accuracy and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f651df95-d5ce-4a1a-8d37-3ccdef908abc",
   "metadata": {},
   "source": [
    "---\n",
    "## Prerequisites\n",
    "1. Use kernel either conda_python3, conda_pytorch_p310 or conda_tensorflow2_p310.\n",
    "2. Install the required packages.\n",
    "3. Access to the Cohere models on Amazon Bedrock and access to the Converse API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62573b-3174-47b5-a6a0-b12e938a725b",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "### Step 0: Install Dependencies and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffffd53d-591c-494d-bb23-50f396f0aa19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U awscli -qU --force --quiet --no-warn-conflicts\n",
    "!pip install boto3==1.34.127 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install numpy==1.26.4 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install opensearch-py -qU --force --quiet --no-warn-conflicts\n",
    "!pip install requests-aws4auth -qU --force --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a763a93-f4c9-46c8-9b33-f7321aa22555",
   "metadata": {},
   "source": [
    "Note: When installing libraries using the pip, you may encounter errors or warnings during the installation process. These are generally not critical and can be safely ignored. However, after installing the libraries, it is recommended to restart the kernel or computing environment you are working in. Restarting the kernel ensures that the newly installed libraries are loaded properly and available for use in your code or workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56106f97-2b41-467a-af1c-f3a63b109113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import os\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from opensearchpy.helpers import bulk\n",
    "import sagemaker\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from requests_aws4auth import AWS4Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935461c9-16f1-42af-9f93-8663860e0c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::709425451936:role/service-role/AmazonSageMaker-ExecutionRole-20240712T100744'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Bedrock Client\n",
    "bedrock_rt= boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "# Create a SageMaker session that will be used when creatin the Opensearch Collection\n",
    "sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "sagemaker_role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197ff74-6900-4e45-9bc3-924ebcfc2049",
   "metadata": {},
   "source": [
    "### Step 1: Read in the userprofile and healthpost schemas and corresponding index files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c48109-9b50-4105-86f0-90e5c6024594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in the userprofile and healthpost schema that are preset that are predefined\n",
    "with open('schemas/userprofile_schema.json', 'r') as file:\n",
    "    userprofile_schema = json.load(file)\n",
    "#open the health posts scheams\n",
    "with open('schemas/healthpost_schema.json', 'r') as file:\n",
    "    healthpost_schema= json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3201d-cc6f-409f-83c9-b6c9da074532",
   "metadata": {},
   "source": [
    "We also have a schemas formatted for the Opensearch index created later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8beb4fe9-c130-4aac-9c1a-980620304f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('schemas/userprofile_schema_index.json', 'r') as file:\n",
    "    userprofile_schema_index = json.load(file)\n",
    "with open('schemas/healthpost_schema_index.json', 'r') as file:\n",
    "    healthpost_schema_index= json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bcf31-8c2c-41fa-bf2c-016d9ce84139",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will need to access all the above information as strings later in the notebook so let's convert the json to strings for later use in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869c4e16-bec4-4cbe-89e1-a5289c6d57f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the correct formatting to send to system prompt\n",
    "userprofile_schema_string= json.dumps(userprofile_schema, indent=2)\n",
    "healthpost_schema_string= json.dumps(healthpost_schema, indent=2)\n",
    "userprofile_index_string= json.dumps(userprofile_schema_index, indent=2)\n",
    "healthpost_index_string= json.dumps(healthpost_schema_index, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034a6b2-b635-4bbd-a37f-2245de23deb2",
   "metadata": {},
   "source": [
    "### Step 2:  Synthetic Data Generation Based on Schemas\n",
    "Now since we have two schemas for healthposts and userprofiles for the health app, let's learn how to generate synthetic data for the schemas using a foundational model. We will use the generate_data() function throughout out the notebook as the single point of calling the LLM of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df32c1b9-9984-40af-b78c-efc0cdfe4063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(bedrock_rt, model_id, system_prompt, query, inference_config):\n",
    "    \"\"\"\n",
    "    Function to call the Bedrock Converse API\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": query}]\n",
    "        }\n",
    "    )\n",
    "    response = bedrock_rt.converse(\n",
    "        modelId=model_id,\n",
    "        system=system_prompt,\n",
    "        messages=messages,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    output = response['output']['message']['content'][0]['text']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8a29d1-9ad8-46b3-88b6-44130ecd07e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set up variables to switch the model_id depending on which model you'd like to test. We will set Cohere Command R+ as default model.\n",
    "model_id_commandR = \"cohere.command-r-v1:0\"\n",
    "model_id_commandR_plus= \"cohere.command-r-plus-v1:0\"\n",
    "model_id = model_id_commandR_plus\n",
    "#we keep it at 0 because we don't want that much creativity\n",
    "inference_config = {\"temperature\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0a61f-dcb7-4ec1-ba00-45957509948b",
   "metadata": {},
   "source": [
    "We will set up two different messages to pass to the Converse API.\n",
    "1. For health posts \n",
    "2. For user profiles\n",
    "\n",
    "We separate the user prompt but keep the same system prompt for both calls. This is standard best practices as the user prompt can be subjective to different tasks at hand but system prompt will stay the same for both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8555f522-56ac-4b30-a880-56c75b627d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message_healthpost= f\"\"\"Please generate 5 Health Post entries based on the following JSON schema. Health Post Schema:{healthpost_schema_string}.\n",
    "        Please provide the generated data in JSON format, do not include any other information in response other than the JSON outputs.\n",
    "        Put each of these additional dictionaries in separate <json> tags.\"\"\"\n",
    "\n",
    "message_userprofile= f\"\"\"Please generate 5 user profile entries based on the following JSON schema. User Profile Schema: {healthpost_schema_string=}\n",
    "        Please provide the generated data in JSON format, do not include any other information in response other than the JSON outputs\n",
    "         Put each of these additional dictionaries in separate <json> tags\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d8a3b99-8a14-49eb-9c5e-9a7ba537647b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = [{\"text\": \"\"\"You are an AI assistant tasked with generating synthetic data for a health tech social media platform. You will be provided a JSON schema. Your job is to create realistic, diverse, and consistent sample data entries based on the schema.\n",
    "\n",
    "Follow these guidelines:\n",
    "1. Generate data that adheres strictly to the provided schemas.\n",
    "2. Create diverse and realistic entries, considering various demographics, health conditions, and interests.\n",
    "3. Ensure consistency between User Profile and Health Post data (e.g., usernames, user IDs).\n",
    "4. Use realistic values for all fields, including dates, metrics, and engagement statistics.\n",
    "5. Generate geolocation data for major cities around the world.\n",
    "6. Create a mix of verified and non-verified users/posts.\n",
    "7. Vary the sentiment scores and engagement metrics realistically.\n",
    "8. Include a range of health interests, fitness levels, and medical conditions.\n",
    "9. Generate realistic content for post titles and content fields.\n",
    "\n",
    "Remember to maintain data privacy by not using real people's information. All data should be fictional but plausible.\n",
    "\n",
    "\"\"\"\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da8aa318-22ae-4ab6-a2c0-acb0a5d54873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Call the generate_data() function and store in a variable for now. You can loop throguh a few examples of this leveraging the same system prompt\n",
    "health_post_data = generate_data(bedrock_rt, model_id, system_prompt, message_healthpost, inference_config)\n",
    "user_profile_data = generate_data(bedrock_rt, model_id, system_prompt, message_userprofile, inference_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce6690-51cf-4a51-9dc2-23535590c9df",
   "metadata": {},
   "source": [
    "We will store our synthetic data in the 'data' folder, let's create it and then add the data to individual files for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59340a3e-a1f7-4ed6-b678-257defbcf3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "164b2aca-59e6-415b-aa04-e74e0d3a2206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data/healthpost_data.json'):  \n",
    "    with open('data/healthpost_data.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(health_posts_dict, f, ensure_ascii=False, indent=4)\n",
    "if not os.path.exists('data/userprofile_data.json'):  \n",
    "    with open('data/userprofile_data.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(user_profile_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52717b15-252a-4a78-8424-54cf04b33a65",
   "metadata": {},
   "source": [
    "Now we have our raw data contained in \"health_posts_dict\" and \"user_profile_dict\" variables. Let's move onto the next step to create an Opensearch Collection, Opensearch Index and ingest the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544d814-916e-4405-96eb-61fe5fecc325",
   "metadata": {},
   "source": [
    "### Step 3: Create Opensearch Collection and Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6ae86f-fba9-4500-924a-102b2626994a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create initial client for opensearch\n",
    "aoss_client = boto3.client('opensearchserverless')\n",
    "suffix = random.randrange(200, 900)\n",
    "identity = boto3.client('sts').get_caller_identity()['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb284c1d-2df9-4f25-b2b4-b2b888f0170a",
   "metadata": {},
   "source": [
    "Find code to step through creating Opensearch Collections. Code sampled from here: https://github.com/aws-samples/Cohere-on-AWS/blob/main/cohere-cookbooks/Embeddings/Cohere_Embeddings_Search.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9454cfbd-66ae-442a-92cb-79b7b8fcad80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_policies_in_oss(es_name, aoss_client, role_arn):\n",
    "    \n",
    "    encryption_policy_name = f\"sample-sp-{suffix}\"\n",
    "    network_policy_name = f\"sample-np-{suffix}\"\n",
    "    access_policy_name = f'sample-ap-{suffix}'\n",
    "\n",
    "    try:\n",
    "        encryption_policy = aoss_client.create_security_policy(\n",
    "            name=encryption_policy_name,\n",
    "            policy=json.dumps(\n",
    "                {\n",
    "                    'Rules': [{'Resource': ['collection/' + es_name],\n",
    "                               'ResourceType': 'collection'}],\n",
    "                    'AWSOwnedKey': True\n",
    "                }),\n",
    "            type='encryption'\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    \n",
    "    try:\n",
    "        network_policy = aoss_client.create_security_policy(\n",
    "            name=network_policy_name,\n",
    "            policy=json.dumps(\n",
    "                [\n",
    "                    {'Rules': [{'Resource': ['collection/' + es_name],\n",
    "                                'ResourceType': 'collection'}],\n",
    "                     'AllowFromPublic': True}\n",
    "                ]),\n",
    "            type='network'\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        access_policy = aoss_client.create_access_policy(\n",
    "            name=access_policy_name,\n",
    "            policy=json.dumps(\n",
    "                [\n",
    "                    {\n",
    "                        'Rules': [\n",
    "                            {\n",
    "                                'Resource': ['collection/' + es_name],\n",
    "                                'Permission': [\n",
    "                                    'aoss:CreateCollectionItems',\n",
    "                                    'aoss:DeleteCollectionItems',\n",
    "                                    'aoss:UpdateCollectionItems',\n",
    "                                    'aoss:DescribeCollectionItems'],\n",
    "                                'ResourceType': 'collection'\n",
    "                            },\n",
    "                            {\n",
    "                                'Resource': ['index/' + es_name + '/*'],\n",
    "                                'Permission': [\n",
    "                                    'aoss:CreateIndex',\n",
    "                                    'aoss:DeleteIndex',\n",
    "                                    'aoss:UpdateIndex',\n",
    "                                    'aoss:DescribeIndex',\n",
    "                                    'aoss:ReadDocument',\n",
    "                                    'aoss:WriteDocument'],\n",
    "                                'ResourceType': 'index'\n",
    "                            }],\n",
    "                        'Principal': [identity, role_arn],\n",
    "                        'Description': 'Easy data policy'}\n",
    "                ]),\n",
    "            type='data'\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        \n",
    "    return encryption_policy, network_policy, access_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68557ef7-d28f-4d90-8a36-3f14f6e438f4",
   "metadata": {},
   "source": [
    "**note**: **Only run the next cell once. If you run it more than once, will error since the policies already exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae988a6-7427-4656-9196-f8dadc937b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Collection\n",
    "es_name = f'es-collection-{suffix}'\n",
    "\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(es_name=es_name,\n",
    "                       aoss_client=aoss_client,\n",
    "                       role_arn=sagemaker_role_arn)\n",
    "#the type should be SEARCH, can be changed to VECTORSEARCH if we want a vectorDB\n",
    "collection = aoss_client.create_collection(name=es_name,type='SEARCH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41503c78-f673-4c94-b76c-7866e486ea8c",
   "metadata": {},
   "source": [
    "**reminder**: only run the above cell ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14e0dc0a-74b5-41c3-91fb-80e0dfec4680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvl2ayqfiqdrqa8w1bxa.us-east-1.aoss.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "#extract the host from the Collection ID to be used \n",
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = collection_id + '.' + region_name + '.aoss.amazonaws.com'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bcc198-fc30-4291-a013-1914ec84f35f",
   "metadata": {},
   "source": [
    "The following code will build the Opensearch client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fad7f93-58cb-4c3e-be25-c744ba964201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = 'aoss'\n",
    "credentials= boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region_name, service, session_token=credentials.token)\n",
    "# Build the OpenSearch client\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "# It can take up to a minute for data access rules to be enforced\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03bb2f-28df-4b9c-ac8a-e2034edc7dc0",
   "metadata": {},
   "source": [
    "**oss_client** is the variable denoted the Opensearch Collection. Now, let's create the two indices for our use case based on the data we read in earlier in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62e5d02f-75eb-4c22-94a4-46d290e08151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#health post\n",
    "healthpost_index = \"healthpost_index\"\n",
    "healthpost_body = {\n",
    "   \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 2,\n",
    "            \"number_of_replicas\": 1\n",
    "        }\n",
    "    },\n",
    "   \"mappings\": healthpost_schema_index['mappings']\n",
    "}\n",
    "\n",
    "#user profile\n",
    "userprofile_index = \"userprofile_index\"\n",
    "userprofile_body = {\n",
    "   \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 2,\n",
    "            \"number_of_replicas\": 1\n",
    "        }\n",
    "    },\n",
    "   \"mappings\": userprofile_schema_index['mappings']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d6e43-c0f9-4fc4-b93c-463af05479fb",
   "metadata": {},
   "source": [
    "Now, we ingest the data and let's check the response was received succesfully.\n",
    "**note** sometimes it can take the collection anywhere from a few minutes to 10 minutes to create. If you are getting errors, wait a few more minutes or check status of your Opensearch Collection in AWS console. The status needs to be \"active\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c28ec01-a980-4522-ba00-856d3e5a3947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response received for the create index -> {'acknowledged': True, 'shards_acknowledged': True, 'index': 'healthpost_index'}\n",
      "response received for the create index -> {'acknowledged': True, 'shards_acknowledged': True, 'index': 'userprofile_index'}\n"
     ]
    }
   ],
   "source": [
    "# We would get an index already exists exception if the index already exists, and that is okay. Ignore that error if it occurs\n",
    "try:\n",
    "    response_health = oss_client.indices.create(healthpost_index, body=healthpost_body) \n",
    "    response_user = oss_client.indices.create(userprofile_index, body=userprofile_body)\n",
    "    print(f\"response received for the create index -> {response_health}\")\n",
    "    print(f\"response received for the create index -> {response_user}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"error, exception={e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d18f57-99ea-476c-96d9-327e5aa99e72",
   "metadata": {},
   "source": [
    "### Step 4: Ingest Synthetic Data into Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aabbafde-e4ce-47f9-bcda-9aebc92059aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in the data created from earlier\n",
    "with open('data/healthpost_data.json', 'r') as file:\n",
    "    healthposts_json = json.load(file)\n",
    "with open('data/userprofile_data.json', 'r') as file:\n",
    "    userprofile_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd555d96-6915-4acd-be04-71531136a2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ingest_data(posts, user, healthpost_index, userprofile_index, oss_client):\n",
    "    actions = []\n",
    "    for k1, k2 in zip(healthposts_json, userprofile_json):\n",
    "        actions.append(\n",
    "        {\n",
    "            \"_index\": healthpost_index,\n",
    "            \"_source\": k1\n",
    "        })\n",
    "        actions.append(\n",
    "        {\n",
    "            \"_index\": userprofile_index,\n",
    "            \"_source\": k2\n",
    "        })\n",
    "    success, failed = bulk(oss_client, actions)\n",
    "    print(f\"Successfully indexed {success} documents\")\n",
    "    print(f\"Failed to index {len(failed)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93ec6973-7e9f-4826-8e29-cd4990277ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 10 documents\n",
      "Failed to index 0 documents\n"
     ]
    }
   ],
   "source": [
    "ingest_data(posts= healthposts_json, user= userprofile_json, healthpost_index=healthpost_index, userprofile_index=userprofile_index, oss_client=oss_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71a747-7e6a-4fa6-9387-eb0b77301013",
   "metadata": {},
   "source": [
    "If we get a succesful statement then we are good to go to the next step to create examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab5ce2-e005-44d0-8409-9f9087bb9ed2",
   "metadata": {},
   "source": [
    "### Step 5: Query All Records in Opensearch Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126a3d7-4112-4573-a844-02e51c581a3c",
   "metadata": {},
   "source": [
    "Below is an example query to match_all the records or return all record in the Opensearch collection.Again the data was generated by the LLM and now we are just confirming that the data resides in the collection and we can start running queries against the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9eaaef1b-c216-46b1-844a-d05e3100022c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_body = {\n",
    "    'query': {\n",
    "        'match_all': {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5106db0f-eba1-4f05-a3e5-9f8a5c9f18cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_oss(query):\n",
    "    #extract the json tags with the function generated beforehand\n",
    "    response = oss_client.search(\n",
    "    index = \"_all\",\n",
    "    body= query\n",
    "    )\n",
    "    return response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2513246c-8f49-47d1-bde4-723855270b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_index': 'healthpost_index', '_id': 'E-9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'post_id': 'post_5', 'user_id': 'user_345', 'username': 'FitnessGuru', 'post_type': 'video', 'title': 'Full-Body HIIT Workout for Beginners', 'content': 'Check out this 30-minute high-intensity interval training routine that will get your heart pumping and muscles burning!', 'created_at': '2023-05-05T12:00:00Z', 'updated_at': '2023-05-05T12:00:00Z', 'tags': ['hiit', 'workout', 'fitness'], 'category': 'exercise', 'likes_count': 1025, 'comments_count': 125, 'shares_count': 85, 'media_urls': ['https://example.com/hiit_workout.mp4'], 'location': {'lat': -22.9068, 'lon': -43.1729}, 'mentioned_users': [], 'health_metrics': {'steps': 5000, 'calories': 450.0, 'heart_rate': 145, 'blood_pressure': {'systolic': 125, 'diastolic': 80}, 'sleep_duration': 7.2}, 'sentiment_score': 0.72, 'is_verified': True}}, {'_index': 'userprofile_index', '_id': 'DO9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'user_id': 'user_1', 'username': 'FitFoodie123', 'post_type': 'recipe', 'title': 'Healthy Quinoa Salad with Roasted Veggies', 'content': 'Looking for a nutritious and delicious meal? Try this quinoa salad packed with roasted veggies like bell peppers, zucchini, and onions. Drizzle with a tangy lemon vinaigrette for an extra burst of flavor!', 'created_at': '2023-05-01T12:34:56Z', 'updated_at': '2023-05-01T12:34:56Z', 'tags': ['healthy', 'vegetarian', 'meal-prep'], 'category': 'food', 'likes_count': 125, 'comments_count': 32, 'shares_count': 18, 'media_urls': ['https://example.com/quinoa-salad.jpg'], 'location': {'lat': 40.7128, 'lon': -74.0059}, 'mentioned_users': [], 'health_metrics': {'steps': 8500, 'calories': 1800.5, 'heart_rate': 72, 'blood_pressure': {'systolic': 120, 'diastolic': 80}, 'sleep_duration': 7.2}, 'sentiment_score': 0.85, 'is_verified': True}}, {'_index': 'healthpost_index', '_id': 'De9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'post_id': 'post_2', 'user_id': 'user_456', 'username': 'RunnerGirl', 'post_type': 'text', 'title': 'Crushed My 10K Personal Best!', 'content': 'Just finished my first 10K race and beat my previous best time by 5 minutes! Feeling accomplished and motivated to keep pushing.', 'created_at': '2023-05-02T14:20:00Z', 'updated_at': '2023-05-02T14:20:00Z', 'tags': ['running', 'fitness', 'personalrecord'], 'category': 'exercise', 'likes_count': 378, 'comments_count': 65, 'shares_count': 28, 'media_urls': ['https://example.com/race_finish.jpg'], 'location': {'lat': 51.5072, 'lon': 0.1276}, 'mentioned_users': [], 'health_metrics': {'steps': 12000, 'calories': 850.0, 'heart_rate': 165, 'blood_pressure': {'systolic': 130, 'diastolic': 85}, 'sleep_duration': 7.0}, 'sentiment_score': 0.92, 'is_verified': False}}, {'_index': 'userprofile_index', '_id': 'EO9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'user_id': 'user_3', 'username': 'MindfulMom', 'post_type': 'article', 'title': 'The Benefits of Mindfulness for Busy Parents', 'content': \"As a parent, it's easy to get caught up in the daily grind and feel overwhelmed. Practicing mindfulness can help reduce stress, increase focus, and improve overall well-being. Here are some simple mindfulness techniques to try...\", 'created_at': '2023-05-03T16:22:41Z', 'updated_at': '2023-05-03T16:22:41Z', 'tags': ['mindfulness', 'parenting', 'self-care'], 'category': 'mental-health', 'likes_count': 210, 'comments_count': 48, 'shares_count': 35, 'media_urls': [], 'location': {'lat': 34.0522, 'lon': -118.2437}, 'mentioned_users': [], 'health_metrics': {}, 'sentiment_score': 0.78, 'is_verified': True}}, {'_index': 'userprofile_index', '_id': 'FO9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'user_id': 'user_5', 'username': 'YogaLover', 'post_type': 'workout', 'title': 'Morning Yoga Flow for Flexibility and Strength', 'content': 'Start your day with this energizing yoga flow! This sequence focuses on building flexibility, strength, and balance. Perfect for all levels. Follow along with the video...', 'created_at': '2023-05-05T07:45:30Z', 'updated_at': '2023-05-05T07:45:30Z', 'tags': ['yoga', 'flexibility', 'strength'], 'category': 'fitness', 'likes_count': 142, 'comments_count': 28, 'shares_count': 20, 'media_urls': ['https://example.com/yoga-flow.mp4'], 'location': {'lat': 35.6895, 'lon': 139.6917}, 'mentioned_users': [], 'health_metrics': {'steps': 2500, 'calories': 250.0, 'heart_rate': 85, 'blood_pressure': {'systolic': 118, 'diastolic': 75}, 'sleep_duration': 7.5}, 'sentiment_score': 0.88, 'is_verified': True}}, {'_index': 'healthpost_index', '_id': 'C-9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'post_id': 'post_1', 'user_id': 'user_123', 'username': 'FitFoodie', 'post_type': 'text', 'title': 'My Healthy Meal Prep for the Week', 'content': \"Prepped a week's worth of nutritious meals with lean proteins, fresh veggies, and whole grains. Staying on track with my fitness goals!\", 'created_at': '2023-05-01T10:30:00Z', 'updated_at': '2023-05-01T10:30:00Z', 'tags': ['mealprep', 'healthyeating', 'fitness'], 'category': 'nutrition', 'likes_count': 245, 'comments_count': 32, 'shares_count': 18, 'media_urls': ['https://example.com/meal_prep_1.jpg', 'https://example.com/meal_prep_2.jpg'], 'location': {'lat': 40.7128, 'lon': -74.0059}, 'mentioned_users': [], 'health_metrics': {'steps': 8500, 'calories': 1850.2, 'heart_rate': 68, 'blood_pressure': {'systolic': 120, 'diastolic': 80}, 'sleep_duration': 7.5}, 'sentiment_score': 0.85, 'is_verified': True}}, {'_index': 'healthpost_index', '_id': 'D-9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'post_id': 'post_3', 'user_id': 'user_789', 'username': 'YogaLover', 'post_type': 'text', 'title': 'Finding Inner Peace Through Meditation', 'content': 'Just finished a rejuvenating yoga and meditation session. Feeling calm, centered, and ready to tackle the day with a clear mind.', 'created_at': '2023-05-03T08:45:00Z', 'updated_at': '2023-05-03T08:45:00Z', 'tags': ['yoga', 'meditation', 'mindfulness'], 'category': 'mentalhealth', 'likes_count': 128, 'comments_count': 18, 'shares_count': 12, 'media_urls': [], 'location': {'lat': 35.6895, 'lon': 139.6917}, 'mentioned_users': [], 'health_metrics': {'steps': 2500, 'calories': 250.0, 'heart_rate': 65, 'blood_pressure': {'systolic': 115, 'diastolic': 75}, 'sleep_duration': 8.0}, 'sentiment_score': 0.78, 'is_verified': False}}, {'_index': 'healthpost_index', '_id': 'Ee9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'post_id': 'post_4', 'user_id': 'user_012', 'username': 'HealthyMom', 'post_type': 'text', 'title': 'Dealing with Postpartum Depression', 'content': \"As a new mom, I've been struggling with postpartum depression. Sharing my journey and seeking support from others who've been through this.\", 'created_at': '2023-05-04T16:10:00Z', 'updated_at': '2023-05-04T16:10:00Z', 'tags': ['postpartumdepression', 'mentalhealth', 'support'], 'category': 'mentalhealth', 'likes_count': 325, 'comments_count': 78, 'shares_count': 42, 'media_urls': [], 'location': {'lat': 19.4326, 'lon': -99.1332}, 'mentioned_users': [], 'health_metrics': {}, 'sentiment_score': 0.35, 'is_verified': True}}, {'_index': 'userprofile_index', '_id': 'Du9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'user_id': 'user_2', 'username': 'RunnerGirl88', 'post_type': 'workout', 'title': 'Crushing My 10K Training!', 'content': 'Just completed a solid 10K training run in preparation for the upcoming city marathon. Feeling strong and motivated! Who else is training for a race this season?', 'created_at': '2023-05-02T09:15:23Z', 'updated_at': '2023-05-02T09:15:23Z', 'tags': ['running', 'training', 'motivation'], 'category': 'fitness', 'likes_count': 78, 'comments_count': 22, 'shares_count': 12, 'media_urls': ['https://example.com/training-run.jpg'], 'location': {'lat': 51.5074, 'lon': -0.1278}, 'mentioned_users': [], 'health_metrics': {'steps': 12000, 'calories': 650.0, 'heart_rate': 165, 'blood_pressure': {'systolic': 125, 'diastolic': 78}, 'sleep_duration': 7.8}, 'sentiment_score': 0.92, 'is_verified': False}}, {'_index': 'userprofile_index', '_id': 'Eu9Gn5EBiT38F8xt-2vb', '_score': 1.0, '_source': {'user_id': 'user_4', 'username': 'GlutenFreeFoodie', 'post_type': 'recipe', 'title': 'Gluten-Free Chocolate Chip Cookies (Dairy-Free Option)', 'content': \"Craving something sweet but need a gluten-free and dairy-free option? These chocolate chip cookies are sure to satisfy your cravings! They're soft, chewy, and absolutely delicious. Get the recipe...\", 'created_at': '2023-05-04T20:38:12Z', 'updated_at': '2023-05-04T20:38:12Z', 'tags': ['gluten-free', 'dairy-free', 'dessert'], 'category': 'food', 'likes_count': 95, 'comments_count': 18, 'shares_count': 25, 'media_urls': ['https://example.com/gf-cookies.jpg'], 'location': {'lat': 19.4326, 'lon': -99.1332}, 'mentioned_users': [], 'health_metrics': {}, 'sentiment_score': 0.91, 'is_verified': False}}]\n"
     ]
    }
   ],
   "source": [
    "output = query_oss(query_body)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3460b-0246-497f-86e5-b2f21e3c0aa5",
   "metadata": {},
   "source": [
    "Above we can see that the model was able to generate a query as well as accurately return data from the Opensearch Collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed6440-dc73-40f8-b015-416509794af1",
   "metadata": {},
   "source": [
    "**note**: if you receive authorization errors eventually, just scroll up and rerun the cell that builds the Opensearch client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71847015-5d3d-4045-b920-9bb92f9d9558",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean Up\n",
    "\n",
    "After we are done, delete the indexes for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d68a7e-a942-45e2-b993-5c70988dbdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_opensearch_serverless_indices(collection_id, client):\n",
    "    # Create a boto3 client for OpenSearch Serverles\n",
    "    try:\n",
    "        client.indices.delete(index='_all')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "delete_opensearch_serverless_indices(collection_id, oss_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a97084-3bd9-49f7-b195-ee97d6b86411",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a369a-a960-4b54-a506-c3593e15e22e",
   "metadata": {},
   "source": [
    "We observed through this notebook how to create synthetic data to improve pace of testing with existing schemas leveraging Cohere Command R+ models. You can leverage a similar approach to integration synthetic data generation into testing for multiple use cases whether that is for Opensearch or other data stores for your applications.\n",
    "\n",
    "This notebook allows you to change the model_id to various Cohere Command models as well to test accuracy and performance. As a next step, you can incorporate reranking search results from the Opensearch collection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
