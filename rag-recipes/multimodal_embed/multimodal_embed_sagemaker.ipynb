{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Using Cohere's Embed V3 Multimodal Model on Amazon Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohere's embeddings model, Embed 3 is an industry-leading AI search model that is designed to transform semantic search and generative AI applications. Cohere Embed 3 is now multimodal and it is capable of generating embeddings from both text and images. This enables enterprises to unlock real value from their vast amounts of data that exist in image form. Businesses can now build systems that accurately search important multimodal assets such as complex reports, ecommerce product catalogs, and design files to boost workforce productivity. This upgrade makes Embed 3 the most generally capable multimodal embedding model on the market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This sample notebook will be using Cohere Embed v3 family of models using Amazon SageMaker:\n",
    "[Cohere Embed Model v3 - English](https://aws.amazon.com/marketplace/pp/prodview-qd64mji3pbnvk)\n",
    "\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Use kernel either *conda_python3*, *conda_pytorch_p310* or *conda_tensorflow2_p310*.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to one of the models listed above. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install striprtf hnswlib --quiet\n",
    "!pip install boto3 --quiet\n",
    "!pip install cohere-aws==0.8.16 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_BEVGykz6uwN",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from cohere_aws import Client\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "from PIL import Image\n",
    "import base64\n",
    "import hnswlib\n",
    "from io import BytesIO\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One you subscribe to the model on AWS Marketplace, a model ARN will be available for you to use and copy as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set model_package variables for endpoint creation\n",
    "model_package = \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-embed-english-v3-7-6d097a095fdd314d90a8400a620cac54\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List existing IAM roles to identify the existing sagemamker execution role\n",
    "iam = boto3.client('iam')\n",
    "roles = iam.list_roles(\n",
    "    PathPrefix='/service-role/',\n",
    "    MaxItems=100\n",
    ")\n",
    "for role in roles['Roles']:\n",
    "    if 'sagemaker.amazonaws.com' in role['AssumeRolePolicyDocument']['Statement'][0]['Principal']['Service']:\n",
    "        execution_role_arn = role['Arn']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a real-time inference endpoint\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Start of section to only run cells once if endpoint does not exist yet**\n",
    "\n",
    "Below is showing how to create a model, endpoint configuration and then the sagemaker endpoint after you have subscribed to the embed V3 model in AWS Marketplace. If you already have your endpoint or it was created on the AWS console, then just replace with the endpoint name you have used after the next 3 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "sagemaker.create_model(ModelName='Model-Cohere-Embed-Model-v3-English-1',\n",
    "    ExecutionRoleArn=execution_role_arn,\n",
    "    PrimaryContainer={\n",
    "        'ModelPackageName': model_package\n",
    "    },\n",
    "    EnableNetworkIsolation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create endpoint config and endpoint\n",
    "sagemaker.create_endpoint_config(EndpointConfigName='EndpointConfig-Cohere-Embed-Model-v3-English-1',\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'variant-1',\n",
    "            'ModelName': 'Model-Cohere-Embed-Model-v3-English-1',\n",
    "            'InstanceType': 'ml.g5.xlarge',\n",
    "            'InitialInstanceCount': 1\n",
    "        }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create endpoint\n",
    "sagemaker.create_endpoint(\n",
    "    EndpointName='Endpoint-Cohere-Embed-Model-v3-English-1',\n",
    "    EndpointConfigName='EndpointConfig-Cohere-Embed-Model-v3-English-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**End of section to only run cells once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to ensure that our endpoint status is \"InService\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check endpoint status, keep running the cell for new updates!\n",
    "def check_endpoint_status(endpoint_name):\n",
    "    try:\n",
    "        response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "        return response['EndpointStatus']\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking endpoint status: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "endpoint_name = 'Endpoint-Cohere-Embed-Model-v3-English-1'\n",
    "status = check_endpoint_status(endpoint_name)\n",
    "if status:\n",
    "    print(f\"Endpoint status: {status}\")\n",
    "else:\n",
    "    print(\"Error getting endpoint status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Sagemaker Embed Function\n",
    "\n",
    "For embedding functionality, Amazon SageMaker doesn't include a native embedding method like Cohere's co.embed() as it's a service designed to be a hosting platform for many models allowing for flexibility of model choice and provider. Below walks through an example function to use and reuse to run the embeddings model on Amazon Sagemaker endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Sagemker Embed function, will be used later\n",
    "def sagemaker_embed(texts, model=\"embed-english-v3.0\", input_type=\"search_document\", truncate=\"END\"):\n",
    "    payload = {\n",
    "        \"texts\": texts,\n",
    "        \"model\": model,\n",
    "        \"input_type\": input_type,\n",
    "        \"truncate\": truncate\n",
    "    }\n",
    "    \n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    return result['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If you want to test the above function, uncomment out the code below\n",
    "#texts = [\"Testing the embeddings\"]\n",
    "#sagemaker_embed(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use Cohere's Multimodel Embeddings V3 to Embed Images\n",
    "For this notebook we have generated 5 images that we will step through embedding via the multimodal embeddings model. We will then show how to run a query against these embeddings to return the most relevant images based on a sample natural language query. \n",
    "\n",
    "You will see a folder called \"content\" which contains both .png images from a sample e-commerce site within the \"image_files\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "id": "C4ETX2Nu66K7",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert an image to a data url\n",
    "def image_to_base64_data_url(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        enc_img = base64.b64encode(f.read()).decode('utf-8')\n",
    "        enc_img = f\"data:image/png;base64,{enc_img}\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"embed-english-v3.0\",\n",
    "        \"input_type\": 'image',\n",
    "        \"embedding_types\": [\"float\"],\n",
    "        \"images\": [enc_img]\n",
    "    }\n",
    "\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = 'content/image_files'\n",
    "files = [f for f in os.listdir(folder_path) if '.ipynb_checkpoints' not in f]\n",
    "#files = os.listdir(folder_path)\n",
    "embedding_objects = []\n",
    "embeddings = []\n",
    "file_paths = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    res = image_to_base64_data_url(file_path)\n",
    "    file_paths.append(file_path)\n",
    "    embeddings.append(res['embeddings']['float'][0])  # Assuming the response structure matches Cohere's\n",
    "    embedding_objects.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for purposes of this notebook we will be using hnsw which is a graph-based algorithm that performs approximate nearest neighbor searches (ANN) in vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the hnsw index for images\n",
    "size = (200, 200)\n",
    "image_index = hnswlib.Index(space='cosine', dim=1024)\n",
    "image_index.init_index(max_elements=len(embeddings), ef_construction=512, M=64)\n",
    "image_index.add_items(embeddings,list(range(len(embeddings))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume for an ecommerce application, a user asked \"Avocado Dog Toy\" when searching for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set these paramters and query your database\n",
    "query = [\"Avocado Dog Toy\"]\n",
    "top_k=5\n",
    "\n",
    "#convert natural language query into embeddings\n",
    "query_emb = sagemaker_embed(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comparing cosine similarity score between the query embedded above and the images that we previously embedded into vectors\n",
    "res = image_index.knn_query(query_emb, k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_index=res[0][0]\n",
    "image_scores=res[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the full list of images grabbed we will iterate through the results\n",
    "for x in range(0,len(image_index)):\n",
    "    print(f\"Ranking of Relevance:{x+1} with a distance of: {image_scores[0]:.2f}\")\n",
    "    img = Image.open(file_paths[image_index[x]])\n",
    "    img_resized = img.resize(size)\n",
    "    display(img_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the endpoint was created by the execution of this notebook, then make sure to delete the endpoint after completion to avoid charges. Skip the below step if you are connecting to an rerank existing endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "#Skip this step if created through the AWS console\n",
    "\n",
    "sagemaker.delete_endpoint(EndpointName='Endpoint-Cohere-Embed-Model-v3-English-1')\n",
    "sagemaker.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note, if you need to create the same endpoint again, run the create_endpoint() function in the cell previously generated only. No need to run create_model() and create_endpoint_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we walked through how to leverage Cohere's Embed V3 multimodal model, capable of generating embeddings from both text and images. This enables enterprises to unlock value from their vast image data, allowing them to build powerful search and recommendation systems across multimodal assets like product catalogs, design files, and business reports. \n",
    "\n",
    "Cohere Embed 3 is now available on Amazon SageMaker, allowing customers to seamlessly deploy this state-of-the-art multimodal embeddings model and leverage it in their own applications. Key use cases include enhanced e-commerce search, efficient data-driven decision making with visual insights, and streamlined creative workflows. Cohere's multimodal embeddings can further improve semantic search when combined with Cohere's Rerank models, providing more contextual relevance to generative AI systems."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1n4FFH75ldi0ekILqr0JPQyx6gotm6lOw",
     "timestamp": 1729110927330
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
