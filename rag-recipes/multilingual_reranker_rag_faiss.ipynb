{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz33G3t6gbOl"
   },
   "source": [
    "# Cohere's Multilingual Models on AWS\n",
    "\n",
    "In today's globalized world, the ability to understand and process multiple languages is becoming increasingly important. [Cohere](https://cohere.com/) has developed a suite of multilingual models designed to tackle this challenge. In this notebook, we'll explore three of Cohere's multilingual models and their potential applications.\n",
    "\n",
    "## Why Multilingual Models Matter\n",
    "\n",
    "Language is a fundamental aspect of human communication and cultural expression. As businesses and organizations expand their reach across borders, the need for effective multilingual solutions becomes paramount. Multilingual models enable seamless communication, bridging language barriers and facilitating cross-cultural understanding.\n",
    "\n",
    "[Cohere's multilingual models](https://aws.amazon.com/marketplace/seller-profile?id=87af0c85-6cf9-4ed8-bee0-b40ce65167e0) offer several benefits:\n",
    "\n",
    "1. **Broad Language Coverage**: Cohere's models support a wide range of languages, allowing you to process and generate content in multiple languages simultaneously.\n",
    "\n",
    "2. **Improved Accuracy**: By training on diverse language data, these models can better capture nuances, idioms, and cultural contexts, resulting in more accurate translations and language processing.\n",
    "\n",
    "3. **Scalability**: With a single multilingual model, you can address language needs across multiple regions, reducing the need for maintaining separate models for each language.\n",
    "\n",
    "4. **Cost-Efficiency**: Deploying a single multilingual model can be more cost-effective than maintaining multiple monolingual models, especially for organizations with global operations.\n",
    "\n",
    "## The Models\n",
    "\n",
    "In this notebook, we'll be working with three of Cohere's multilingual models:\n",
    "\n",
    "1. **Cohere Command R+**: A powerful Large Language Model (LLM) capable of understanding and generating text in multiple languages.\n",
    "\n",
    "2. **Cohere Embed Multilingual V3**: An embedding model designed to encode text from various languages into dense vector representations, enabling efficient similarity comparisons and semantic search.\n",
    "\n",
    "3. **Cohere Rerank Multilingual V3**: A reranker model used in conjunction with the Retrieval-Augmented Generation (RAG) approach, which enhances the relevance and accuracy of generated text by leveraging retrieved information from a knowledge base.\n",
    "\n",
    "Throughout this notebook, we'll explore practical examples and use cases for these models, showcasing their capabilities in areas such as multilingual content generation, and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "1. Use kernel either `conda_python3`, `conda_pytorch_p310` or `conda_tensorflow2_p310`.\n",
    "2. Install the required packages.\n",
    "3. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "4. To deploy a reranker model from Cohere, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [cohere-rerank-multilingual](https://aws.amazon.com/marketplace/pp/prodview-ydysc72qticsw)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Delete the endpoint](#H.-Delete-the-endpoint)\n",
    "3. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "Here, we will install all the required dependencies to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets import the required modules to run the notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H787BXXYvD0a",
    "outputId": "04ef5e04-7760-4d40-deeb-663536b38f20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia==1.4.0 --quiet\n",
    "!pip install cohere-aws==0.8.16 --quiet\n",
    "!pip install faiss-cpu==1.8.0 --quiet\n",
    "!pip install langchain-text-splitters==0.2.2 --quiet\n",
    "!pip install numpy==1.26.4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from cohere_aws import Client\n",
    "import faiss\n",
    "import json\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import re\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSB0pnt0gbOo"
   },
   "source": [
    "## Step 2 - Getting some data\n",
    "\n",
    "To get started, we'll leverage data from wikipedia to answer questions about the diverse culinary traditions across different countries and languages. Our goal is to showcase Cohere's multilingual capabilities by crawling wikipedia to get cuisine information of the United States, Mexico, and Germany from their respective language editions of Wikipedia. \n",
    "\n",
    "By retrieving and analyzing data from these multilingual sources, we can gain insights into the unique flavors, ingredients, and cultural influences that shape the food heritage of each nation. This approach not only allows us to explore the richness of global cuisine but also demonstrates the power of multilingual language models in accessing and processing information from diverse linguistic sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USA - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# English\n",
    "wikipedia.set_lang('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP-bWt9XgbOq",
    "outputId": "72276fb2-0d6b-415d-af74-452a013ae84b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has roughly 19051 words.\n"
     ]
    }
   ],
   "source": [
    "# we'll get some wikipedia data\n",
    "article = wikipedia.page('American Cuisine')\n",
    "en_text = article.content\n",
    "print(f\"The text has roughly {len(en_text.split())} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American cuisine consists of the cooking style and traditional dishes prepared in the United States. It has been significantly influenced by Europeans, Indigenous Americans, Africans, Latin Americans, Asians, Pacific Islanders, and many other cultures and traditions. Principal influences on American cuisine are European, Native American, soul food, regional heritages including Cajun, Louisiana Creole, Pennsylvania Dutch, Mormon foodways, Texan, Tex-Mex, New Mexican, and Tlingit, and the cuisines of immigrant groups such as Chinese American, Italian American, Jewish American, Greek American and Mexican American. The large size of America and its long history of immigration have created an especially diverse cuisine that varies by region. \n",
      "American cooking dates back to the traditions of the Native Americans, whose diet included a mix of farmed and hunted food, and varied widely across the continent. The Colonial period created a mix of new world and Old World cookery, and brought with i\n"
     ]
    }
   ],
   "source": [
    "print(en_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mexico - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spanish\n",
    "wikipedia.set_lang('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has roughly 15592 words.\n"
     ]
    }
   ],
   "source": [
    "# we'll get some wikipedia data\n",
    "article = wikipedia.page('Gastronomia de Mexico')\n",
    "es_text = article.content\n",
    "print(f\"The text has roughly {len(es_text.split())} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La gastronomía mexicana es el conjunto de platillos y técnicas culinarias de México que forman parte de las tradiciones y vida común de sus habitantes, enriquecida por las aportaciones de las distintas regiones del país, que deriva de la experiencia del México prehispánico con la cocina española, entre otras. El 16 de noviembre de 2010, la gastronomía mexicana fue reconocida como Patrimonio cultural inmaterial de la Humanidad por la Unesco.[1]​[2]​\n",
      "La cocina mexicana ha sido influida y ha influido a su vez a cocinas de otras culturas, como la estadounidense, española, francesa, italiana, africana, del Oriente Medio y asiática. Es testimonio de la cultura histórica del país: muchos platillos se originaron en el México prehispánico y otros momentos importantes de su historia. Existe en ella una amplia gama de sabores, colores, olores, texturas e influencias que la convierten en un gran atractivo para nacionales y extranjeros: México es famoso por su gastronomía.\n",
      "La base de la cocina mexi\n"
     ]
    }
   ],
   "source": [
    "print(es_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Germany - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# German\n",
    "wikipedia.set_lang('de') # Deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has roughly 3067 words.\n"
     ]
    }
   ],
   "source": [
    "# we'll get some wikipedia data\n",
    "article = wikipedia.page('Deutsches Essen')\n",
    "de_text = article.content\n",
    "print(f\"The text has roughly {len(de_text.split())} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Als deutsche Küche bezeichnet man allgemein die Küche Deutschlands. Sie ist gekennzeichnet durch starke regionale Unterschiede und an den Außengrenzen historisch bedingt geprägt durch die Einflüsse der Küche der Nachbarländer (z. B. Frankreich, Österreich, Polen). Starke Regionalküchen gibt es auf den Gebieten ehemals eigenständiger deutscher Staaten (Bayern, Baden) und Großregionen (Franken, Schwaben, Rheinland).\n",
      "\n",
      "Typisch ist eine sättigende Mahlzeit am Morgen, das Frühstück. Traditionell war die Hauptmahlzeit des Tages das Mittagessen, das etwa zwischen 12 und 14 Uhr eingenommen wird. Am Nachmittag wird häufig eine Zwischenmahlzeit verzehrt, die beispielsweise aus Kaffee und Gebäck bestehen kann. Das Abendessen war früher eine meist kleinere Mahlzeit, die oftmals nur aus ein paar belegten Brotscheiben bestand. Heute ist das Abendessen oft die Hauptmahlzeit des Tages.\n",
      "\n",
      "Der Fleischkonsum liegt in Deutschland bei etwa 60 kg im Jahr pro Person; 59 % entfallen dabei auf Schweinefleisch, d\n"
     ]
    }
   ],
   "source": [
    "print(de_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1aJ7hKGgbOr"
   },
   "source": [
    "## Step 3 - Vector Indexing\n",
    "\n",
    "We index the document in an open-source vectorstore called FAISS. This requires chunking the documents, creating embeddings, and indexing them into FAISS.\n",
    "\n",
    "To efficiently store and retrieve relevant information from our multilingual data, we will leverage [FAISS](https://ai.meta.com/tools/faiss/) (Facebook AI Similarity Search), an open-source library for efficient similarity search and clustering of dense vectors. FAISS allows us to index and search large collections of embeddings, enabling quick retrieval of the most relevant documents or passages based on their vector representations. \n",
    "\n",
    "Our process involves chunking the retrieved documents into smaller, more manageable segments, creating dense vector embeddings for each chunk using Cohere's Embed Multilingual V3, and indexing these embeddings into FAISS. \n",
    "\n",
    "By utilizing FAISS's powerful similarity search capabilities, we can quickly identify the most relevant chunks of information based on their semantic similarity to a given query or context. This approach not only facilitates efficient information retrieval but also unlocks the potential for advanced applications such as semantic search, question answering, and knowledge base construction from multilingual sources. FAISS's scalability and performance make it an ideal choice for handling large volumes of embeddings, ensuring responsive and accurate results even with extensive multilingual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhXW7iHC1-Q6",
    "outputId": "d68ac348-4b73-4c6a-a445-6c510bdb0881",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For chunking let's use langchain to help us split the text\n",
    "def get_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512, # Limiting chunk size for embedding model\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    # Split the text into chunks with some overlap\n",
    "    chunks_ = text_splitter.create_documents([text])\n",
    "    chunks = [c.page_content for c in chunks_]\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USA - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been broken down in 362 chunks.\n"
     ]
    }
   ],
   "source": [
    "en_chunks = get_chunks(en_text)\n",
    "print(f\"The text has been broken down in {len(en_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mexico - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been broken down in 289 chunks.\n"
     ]
    }
   ],
   "source": [
    "es_chunks = get_chunks(es_text)\n",
    "print(f\"The text has been broken down in {len(es_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Germany - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been broken down in 71 chunks.\n"
     ]
    }
   ],
   "source": [
    "de_chunks = get_chunks(de_text)\n",
    "print(f\"The text has been broken down in {len(de_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8g0sE2hgbOs"
   },
   "source": [
    "### Create embeddings for every text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    texts,\n",
    "    batch_size=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert text into embeddings.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        texts (list) : The texts to send to the embedding model.\n",
    "        batch_size (int): Batch size to limit the number of chunks sent to the embedding model.\n",
    "\n",
    "    Returns:\n",
    "        response (JSON): The embeddings that the model generated.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        body = {\n",
    "            \"texts\": batch_texts,\n",
    "            \"input_type\": \"search_document\"\n",
    "        }\n",
    "        # Send the message.\n",
    "        response = bedrock_client.invoke_model(modelId=model_id, body=json.dumps(body))\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        \n",
    "        embeddings.extend(response_body[\"embeddings\"])\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define bedrock client\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USA - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just computed 362 embeddings.\n"
     ]
    }
   ],
   "source": [
    "en_embeddings = generate_embeddings(bedrock_client, \"cohere.embed-multilingual-v3\", en_chunks)\n",
    "print(f\"We just computed {len(en_embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mexico - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just computed 289 embeddings.\n"
     ]
    }
   ],
   "source": [
    "es_embeddings = generate_embeddings(bedrock_client, \"cohere.embed-multilingual-v3\", es_chunks)\n",
    "print(f\"We just computed {len(es_embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Germany - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just computed 71 embeddings.\n"
     ]
    }
   ],
   "source": [
    "de_embeddings = generate_embeddings(bedrock_client, \"cohere.embed-multilingual-v3\", de_chunks)\n",
    "print(f\"We just computed {len(de_embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM6vKeypgbOs"
   },
   "source": [
    "### Store embeddings into FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USA - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an index\n",
    "en_vectorstore = faiss.IndexFlatL2(1024)\n",
    "\n",
    "# Add data to the index\n",
    "en_vectorstore.add(np.array(en_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mexico - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an index\n",
    "es_vectorstore = faiss.IndexFlatL2(1024)\n",
    "\n",
    "# Add data to the index\n",
    "es_vectorstore.add(np.array(es_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Germany - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an index\n",
    "de_vectorstore = faiss.IndexFlatL2(1024)\n",
    "\n",
    "# Add data to the index\n",
    "de_vectorstore.add(np.array(de_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NGVurZgbOs"
   },
   "source": [
    "## Step 4: RAG: Retrieve relevant chunks from the vector database\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a powerful approach that combines the strengths of retrieval and generation models for natural language processing tasks. In this approach, we first utilize an embedding model to identify relevant information from FAISS based on the input query. The retrieved information is then incorporated into a large language model, like Cohere's Command R+, which uses this additional context to generate more informed and accurate outputs. By leveraging the vast knowledge contained in multilingual sources, RAG enables us to produce high-quality, factual responses that go beyond the model's initial training data. This approach is particularly valuable for tasks like question answering, where relevant external knowledge can significantly improve the quality and completeness of the generated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility function for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(vectorstore, question, chunks, k=4):\n",
    "    # Embed the user question\n",
    "    query = generate_embeddings(bedrock_client, \"cohere.embed-multilingual-v3\", [question])\n",
    "    \n",
    "    # Retrieve the top K indices from the vector database\n",
    "    D, top_indices = vectorstore.search(np.array(query), k)\n",
    "    \n",
    "    top_indices.sort()\n",
    "    \n",
    "    # Retrieve the top K most similar chunks\n",
    "    top_chunks_after_retrieval = [re.sub(r\"\\t+|\\n+\", \"\", chunks[i]) for i in top_indices[0]]\n",
    "    \n",
    "    return top_chunks_after_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility function for conversation with Bedrock converse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history=[],\n",
    "    temperature=0.5,\n",
    "    max_tokens=400,\n",
    "    top_p=0.95\n",
    "):\n",
    "    \"\"\"\n",
    "    Sends messages to a model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        system_prompt (str) : The system prompt for the model to use.\n",
    "        prompt (str) : The message/question to send to the model.\n",
    "        chat_history (list): The chat history from user and assistant.\n",
    "\n",
    "    Returns:\n",
    "        response (str): The text generated output from the model.\n",
    "        chat_history (str): The full conversation between user and assistant that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompts = [\n",
    "        {\n",
    "            \"text\": system_prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    chat_history.extend(messages)\n",
    "\n",
    "    # Base inference parameters.\n",
    "    inference_config = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxTokens\": max_tokens,\n",
    "        \"topP\": top_p,\n",
    "    }\n",
    "\n",
    "    # Additional inference parameters to use.\n",
    "    additional_model_fields = {}\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "    chat_history.append(response[\"output\"][\"message\"])\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"], chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the system prompt and guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant with expertise in American cuisine. Your knowledge is based solely on the information provided between the <documents> and </documents> tags.\n",
    "\n",
    "Before answering any questions, first check if the user has provided information between the <documents> and </documents> tags. If no information is provided, respond with the following JSON:\n",
    "\n",
    "{\n",
    "    \"answer\": \"I do not have enough information to answer that question.\"\n",
    "}\n",
    "\n",
    "If documents are provided, your task is to answer questions accurately and concisely, using only the details from the given documents. Do not use your own knowledge or any external sources to answer the questions, even if you know the answer.\n",
    "\n",
    "If a question cannot be fully answered using the provided documents, respond with the following JSON:\n",
    "\n",
    "{\n",
    "    \"answer\": \"I do not have enough information to answer that question.\"\n",
    "}\n",
    "\n",
    "All responses must be in valid JSON format, with the 'answer' key containing the actual response text.\n",
    "\n",
    "To provide transparency, include your reasoning process with the 'thinking' key as the following format:\n",
    "\n",
    "{\n",
    "    \"answer\": \"Your response here\",\n",
    "    \"thinking\": \"Your reasoning process here\"\n",
    "}\n",
    "\n",
    "Be concise and objective in your responses, without any personal opinions or subjective statements.\n",
    "\"\"\"\n",
    "prompt_template = \"<documents>\\n{documents}\\n</documents>\\n\\nQuestion: {question}\\nThink step-by-step.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model ID parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"cohere.command-r-plus-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y2HTxspKgbOs"
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "question = \"What are some popular regional dishes in American cuisine?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": \"I do not have enough information to answer that question.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(documents=\"\", question=question)\n",
    "\n",
    "response, chat_history = generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieved top K most relevant chunks from FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting number of nearest neighbours\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. USA - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 4 chunks after retrieval: \n",
      "== American cuisine consists of the cooking style and traditional dishes prepared in the United States. It has been significantly influenced by Europeans, Indigenous Americans, Africans, Latin Americans, Asians, Pacific Islanders, and many other cultures and traditions. Principal influences on American cuisine are European, Native American, soul food, regional heritages including Cajun, Louisiana Creole, Pennsylvania Dutch, Mormon foodways, Texan, Tex-Mex, New Mexican, and Tlingit, and the cuisines of\n",
      "== Highlights of American cuisine include milkshakes, barbecue, and a wide range of fried foods. Many quintessential American dishes are unique takes on food originally from other culinary traditions, including pizza, hot dogs, and Tex-Mex. Regional highlights include a range of fish dishes in the coastal states, gumbo, and cheesesteak. American cuisine has specific foods that are eaten on holidays, such as a turkey at Thanksgiving dinner or Christmas dinner. Modern American cuisine includes a focus on fast\n",
      "== Modern American cuisine includes a focus on fast food, as well as take-out food, which is often ethnic. There is also a vibrant culinary scene in the country surrounding televised celebrity chefs.\n",
      "== === Common dishes found on a regional level ===== Ethnicity-specific and immigrant influence ==\n"
     ]
    }
   ],
   "source": [
    "top_chunks_after_retrieval = rag(en_vectorstore, question, en_chunks, k)\n",
    "\n",
    "print(f\"Here are the top {k} chunks after retrieval: \")\n",
    "for t in top_chunks_after_retrieval:\n",
    "    print(\"== \" + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"answer\": \"Some popular regional dishes in American cuisine include gumbo, cheesesteak, and various fish dishes from the coastal states. Barbecue and fried foods are also highlights, and each region may have its own unique variations.\",\n",
      "    \"thinking\": \"The text mentions gumbo and cheesesteak as regional highlights, as well as fish dishes from coastal states. It also mentions barbecue and fried foods as popular American cuisine, which likely includes regional variations.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "prompt = prompt_template.format(documents=top_chunks_after_retrieval, question=question)\n",
    "\n",
    "response, chat_history = generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mexico - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "question = \"¿Cuáles son algunos platos regionales populares en la cocina mexicana?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 4 chunks after retrieval: \n",
      "== nacionales y extranjeros: México es famoso por su gastronomía.\n",
      "== La diversidad es la característica esencial de la cocina mexicana, y es la comida regional uno de sus aspectos fundamentales. Cada estado mexicano y región poseen sus propias recetas y tradiciones culinarias.[4]​ Ejemplos de comidas regionales son platillos como el caldillo duranguense (Durango), cochinita pibil (yucateca), el mole oaxaqueño, el mole poblano y el chile en nogada (Puebla), los múltiples tipos de pozole, el cabrito (coahuilense y neoleonense), el pan de cazón campechano, el churipo y las\n",
      "== país y otras zonas tropicales, se da una amplia diversidad de sabores con una cantidad hasta ahora desconocida de platillos y recetarios locales.\n",
      "== == Variantes regionales ==Si bien existen platos nacionales (como el mole, los chiles en nogada o la cochinita pibil), muchos autores han definido la gastronomía mexicana más como un conjunto de cocinas regionales, que no es más que una prolongación de la diversidad cultural, geográfica, histórica y étnica del país.== Véase también ==== Referencias ==== Bibliografía ==\n"
     ]
    }
   ],
   "source": [
    "top_chunks_after_retrieval = rag(es_vectorstore, question, es_chunks, k)\n",
    "\n",
    "print(f\"Here are the top {k} chunks after retrieval: \")\n",
    "for t in top_chunks_after_retrieval:\n",
    "    print(\"== \" + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": \"Algunos platos regionales populares en México incluyen el caldillo duranguense, la cochinita pibil, el mole oaxaqueño y poblano, el chile en nogada, el pozole, el cabrito, el pan de cazón y el churipo.\",\n",
      "    \"thinking\": \"La pregunta se refiere específicamente a los platos regionales mexicanos, por lo que me concentro en las secciones del texto que mencionan la diversidad culinaria regional y los ejemplos de platos característicos de cada región.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(documents=top_chunks_after_retrieval, question=question)\n",
    "\n",
    "response, chat_history = generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Germany - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "question = \"Was sind einige beliebte regionale Gerichte der deutschen Küche?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 4 chunks after retrieval: \n",
      "== Als deutsche Küche bezeichnet man allgemein die Küche Deutschlands. Sie ist gekennzeichnet durch starke regionale Unterschiede und an den Außengrenzen historisch bedingt geprägt durch die Einflüsse der Küche der Nachbarländer (z. B. Frankreich, Österreich, Polen). Starke Regionalküchen gibt es auf den Gebieten ehemals eigenständiger deutscher Staaten (Bayern, Baden) und Großregionen (Franken, Schwaben, Rheinland).\n",
      "== Basilikum und Oregano sowie typische mediterrane Gerichte übernommen (siehe auch französische Küche, italienische Küche, griechische Küche, türkische Küche und spanische Küche).\n",
      "== mit Zwiebeln). Genauso geschätzt werden Miesmuschelgerichte, die berühmte Bergische Kaffeetafel des Bergischen Landes, Schnippelbohnensuppe, Pfannkuchen, Reibekuchen und Himmel un Ääd.\n",
      "== Bürgerliche KücheHausmannskostKüche der Deutschen Demokratischen RepublikDeutsche Küche in den Vereinigten StaatenPeter Peter: Kulturgeschichte der deutschen Küche. C. H. Beck-Verlag, München 2008, ISBN 978-3-406-57224-1Deutsche Küche. 2. Auflg., Teubner-Verlag, München 2007, ISBN 978-3-8338-0464-9\n"
     ]
    }
   ],
   "source": [
    "top_chunks_after_retrieval = rag(de_vectorstore, question, de_chunks, k)\n",
    "\n",
    "print(f\"Here are the top {k} chunks after retrieval: \")\n",
    "for t in top_chunks_after_retrieval:\n",
    "    print(\"== \" + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": \"Zu den beliebten regionalen Gerichten der deutschen Küche gehören unter anderem: Bergische Kaffeetafel, Schnippelbohnensuppe, Pfannkuchen, Reibekuchen und Himmel un Ääd (ein Kartoffelgericht mit Zwiebeln). Auch Miesmuschelgerichte sind beliebt.\",\n",
      "    \"thinking\": \"Die Frage kann direkt mit Informationen aus den bereitgestellten Dokumenten beantwortet werden.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(documents=top_chunks_after_retrieval, question=question)\n",
    "\n",
    "response, chat_history = generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzcpds3VgbOt"
   },
   "source": [
    "## Step 2 - RAG: Rerank the chunks retrieved from the vector database\n",
    "\n",
    "Building upon the power of Retrieval-Augmented Generation (RAG), we can further enhance the relevance and accuracy of our generated outputs by incorporating a reranker model. In this approach, we first retrieve a set of potentially relevant information from our knowledge base using a retrieval model like Cohere's Embed Multilingual V3. These retrieved pieces of information are then reranked using a specialized reranker model, such as Cohere's Rerank Multilingual V3, which scores each retrieved item based on its relevance to the input query or context. The top-ranked items are then passed to the generative language model, Cohere's Command R+, which generates the final output while considering this highly relevant contextual information. By incorporating a reranker, we can effectively filter out irrelevant or tangential information, ensuring that the generated responses are focused, coherent, and directly address the specific query or context at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create cohere client\n",
    "co = Client(region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"cohere-rerank-multilingual-v3-0\"\n",
    "is_endpoint_created = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create endpoint, SKIP THIS STEP IF THE ENDPOINT WAS CREATED ON THE AWS CONSOLE\n",
    "if not is_endpoint_created:\n",
    "    model_package_arn = \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-rerank-multilingual-v3--13dba038aab73b11b3f0b17fbdb48ea0\"\n",
    "    co.create_endpoint(arn=model_package_arn, endpoint_name=endpoint_name, instance_type=\"ml.g5.xlarge\", n_instances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the endpoint is already created, you just need to connect to it\n",
    "co.connect_to_endpoint(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility function for RAG with Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_with_reranker(vectorstore, question, chunks, k=4, top_n=3):\n",
    "    # Embed the user question\n",
    "    query = generate_embeddings(bedrock_client, \"cohere.embed-multilingual-v3\", [question])\n",
    "    \n",
    "    # Retrieve the top K indices from the vector database\n",
    "    D, top_indices = vectorstore.search(np.array(query), k)\n",
    "    \n",
    "    top_indices.sort()\n",
    "    \n",
    "    # Retrieve the top K most similar chunks\n",
    "    top_chunks_after_retrieval = [re.sub(r\"\\t+|\\n+\", \"\", chunks[i]) for i in top_indices[0]]\n",
    "    \n",
    "    response = co.rerank(\n",
    "        query=question,\n",
    "        documents=top_chunks_after_retrieval,\n",
    "        top_n=top_n\n",
    "    )\n",
    "\n",
    "    top_chunks_after_rerank = [result.document['text'] for result in response]  \n",
    "    return top_chunks_after_rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "question = \"What are some popular regional dishes in American cuisine?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 3 chunks after rerank: \n",
      "== Highlights of American cuisine include milkshakes, barbecue, and a wide range of fried foods. Many quintessential American dishes are unique takes on food originally from other culinary traditions, including pizza, hot dogs, and Tex-Mex. Regional highlights include a range of fish dishes in the coastal states, gumbo, and cheesesteak. American cuisine has specific foods that are eaten on holidays, such as a turkey at Thanksgiving dinner or Christmas dinner. Modern American cuisine includes a focus on fast\n",
      "== American cuisine consists of the cooking style and traditional dishes prepared in the United States. It has been significantly influenced by Europeans, Indigenous Americans, Africans, Latin Americans, Asians, Pacific Islanders, and many other cultures and traditions. Principal influences on American cuisine are European, Native American, soul food, regional heritages including Cajun, Louisiana Creole, Pennsylvania Dutch, Mormon foodways, Texan, Tex-Mex, New Mexican, and Tlingit, and the cuisines of\n",
      "== The various ethnicities originating from the early gastronomy and cuisines of the New World, Latin American cuisine, and North American cuisine:Native Americans in the United States and Native American cuisineAfrican Americans and Soul food.Puerto Rican cuisineMexican Americans and Mexican-American cuisine; as well as related regional cuisines:Tex-Mex (regional Texas and Mexican fusion)Some aspects of \"Southwestern cuisine\".\n"
     ]
    }
   ],
   "source": [
    "top_chunks_after_rerank = rag_with_reranker(en_vectorstore, question, en_chunks, k=10, top_n=3)\n",
    "\n",
    "print(\"Here are the top 3 chunks after rerank: \")\n",
    "for t in top_chunks_after_rerank:\n",
    "    print(\"== \" + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"answer\": \"Popular regional dishes in American cuisine include fish specialties from coastal states, gumbo, cheesesteak, Tex-Mex, and Cajun and Creole dishes from Louisiana.\",\n",
      "    \"thinking\": \"The documents mention several regional specialties, including dishes influenced by specific cultural and regional heritages.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(documents=top_chunks_after_rerank, question=question)\n",
    "\n",
    "response, chat_history = generate_conversation(\n",
    "    bedrock_client,\n",
    "    model_id,\n",
    "    system_prompt,\n",
    "    prompt,\n",
    "    chat_history\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we explored Cohere's multilingual models, including Command R+, Embed Multilingual V3, and Rerank Multilingual V3 for reranking retrieved information, RAG significantly enhances the relevance and accuracy of generated content.\n",
    "\n",
    "The reranking step, in particular, proved invaluable in improving the quality of generated text by incorporating relevant information from a knowledge base with support for multiple languages. This approach not only ensures factual accuracy but also provides context-specific responses tailored to the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
